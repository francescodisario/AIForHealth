
Loading Dataset
shape of testing label[0]: (36, 13, 13, 8)
shape of testing label[1]: (36, 26, 26, 8)
shape of testing label[2]: (36, 52, 52, 8)
shape of testing img: (36, 416, 416, 3)
shape of validation label[0]: (36, 13, 13, 8)
shape of validation label[1]: (36, 26, 26, 8)
shape of validation label[2]: (36, 52, 52, 8)
shape of validation img: (36, 416, 416, 3)
shape of training label[0]: (296, 13, 13, 8)
shape of training label[1]: (296, 26, 26, 8)
shape of training label[2]: (296, 52, 52, 8)
shape of training img: (296, 416, 416, 3)
epoch  1: loss = 0.0561
epoch  2: loss = 0.0312
epoch  3: loss = 0.0254
epoch  4: loss = 0.0215
epoch  5: loss = 0.0174
epoch  6: loss = 0.0181
epoch  7: loss = 0.0163
epoch  8: loss = 0.0170
epoch  9: loss = 0.0193
epoch 10: loss = 0.0150
epoch 11: loss = 0.0128
epoch 12: loss = 0.0100
epoch 13: loss = 0.0083
epoch 14: loss = 0.0071
epoch 15: loss = 0.0064
epoch 16: loss = 0.0054
epoch 17: loss = 0.0053
epoch 18: loss = 0.0073
epoch 19: loss = 0.0064
epoch 20: loss = 0.0066
epoch 21: loss = 0.0070
epoch 22: loss = 0.0067
epoch 23: loss = 0.0089
epoch 24: loss = 0.0086
epoch 25: loss = 0.0086
epoch 26: loss = 0.0078
epoch 27: loss = 0.0086
epoch 28: loss = 0.0070
epoch 29: loss = 0.0082
epoch 30: loss = 0.0120
epoch 31: loss = 0.0156
epoch 32: loss = 0.0125
epoch 33: loss = 0.0108
epoch 34: loss = 0.0096
epoch 35: loss = 0.0074
epoch 36: loss = 0.0072
epoch 37: loss = 0.0045
epoch 38: loss = 0.0047
epoch 39: loss = 0.0049
epoch 40: loss = 0.0059
epoch 41: loss = 0.0044
epoch 42: loss = 0.0044
epoch 43: loss = 0.0041
epoch 44: loss = 0.0036
epoch 45: loss = 0.0032
epoch 46: loss = 0.0036
epoch 47: loss = 0.0037
epoch 48: loss = 0.0031
epoch 49: loss = 0.0037
epoch 50: loss = 0.0032
epoch 51: loss = 0.0023
epoch 52: loss = 0.0016
epoch 53: loss = 0.0016
epoch 54: loss = 0.0020
epoch 55: loss = 0.0015
epoch 56: loss = 0.0018
epoch 57: loss = 0.0016
epoch 58: loss = 0.0021
epoch 59: loss = 0.0020
epoch 60: loss = 0.0021
epoch 61: loss = 0.0021
epoch 62: loss = 0.0015
epoch 63: loss = 0.0012
epoch 64: loss = 0.0018
epoch 65: loss = 0.0016
epoch 66: loss = 0.0013
epoch 67: loss = 0.0010
epoch 68: loss = 0.0012
epoch 69: loss = 0.0010
epoch 70: loss = 0.0012
epoch 71: loss = 0.0012
epoch 72: loss = 0.0014
epoch 73: loss = 0.0011
epoch 74: loss = 0.0014
epoch 75: loss = 0.0017
epoch 76: loss = 0.0019
epoch 77: loss = 0.0013
epoch 78: loss = 0.0007
epoch 79: loss = 0.0006
epoch 80: loss = 0.0003
epoch 81: loss = 0.0005
epoch 82: loss = 0.0003
epoch 83: loss = 0.0007
epoch 84: loss = 0.0008
epoch 85: loss = 0.0007
epoch 86: loss = 0.0007
epoch 87: loss = 0.0010
epoch 88: loss = 0.0005
epoch 89: loss = 0.0003
epoch 90: loss = 0.0010
epoch 91: loss = 0.0005
epoch 92: loss = 0.0020
epoch 93: loss = 0.0019
epoch 94: loss = 0.0036
epoch 95: loss = 0.0037
epoch 96: loss = 0.0045
epoch 97: loss = 0.0036
epoch 98: loss = 0.0043
epoch 99: loss = 0.0049
epoch 100: loss = 0.0046
epoch 101: loss = 0.0048
epoch 102: loss = 0.0028
epoch 103: loss = 0.0020
epoch 104: loss = 0.0010
epoch 105: loss = 0.0016
epoch 106: loss = 0.0016
epoch 107: loss = 0.0020
epoch 108: loss = 0.0020
epoch 109: loss = 0.0021
epoch 110: loss = 0.0015
epoch 111: loss = 0.0013
epoch 112: loss = 0.0008
epoch 113: loss = 0.0005
epoch 114: loss = 0.0006
epoch 115: loss = 0.0007
epoch 116: loss = 0.0005
epoch 117: loss = 0.0006
epoch 118: loss = 0.0008
epoch 119: loss = 0.0003
epoch 120: loss = 0.0005
epoch 121: loss = 0.0003
epoch 122: loss = 0.0002
epoch 123: loss = 0.0003
epoch 124: loss = 0.0001
epoch 125: loss = 0.0000
Epoch 1/2
WARNING:tensorflow:AutoGraph could not transform <function wrap_yolo_loss.<locals>.yolo_loss at 0x7f5e4bd64c10> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: invalid syntax (tmpsop4mbj6.py, line 39)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <function wrap_yolo_loss.<locals>.yolo_loss at 0x7f5e603c4ca0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: invalid syntax (tmpffqucdrr.py, line 39)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <function wrap_yolo_loss.<locals>.yolo_loss at 0x7f5da0156ca0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: invalid syntax (tmprcvj__qf.py, line 39)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

 9/60 [===>..........................] - ETA: 19s - loss: 1549.6294 - concatenate_2_loss: 199.3494 - concatenate_3_loss: 253.5222 - concatenate_4_loss: 1096.7578











60/60 [==============================] - 42s 479ms/step - loss: 1000.0671 - concatenate_2_loss: 133.9240 - concatenate_3_loss: 159.4018 - concatenate_4_loss: 706.7413 - val_loss: 574.2290 - val_concatenate_2_loss: 115.2826 - val_concatenate_3_loss: 116.0753 - val_concatenate_4_loss: 342.8711
Epoch 2/2













60/60 [==============================] - 26s 436ms/step - loss: 310.0570 - concatenate_2_loss: 71.0145 - concatenate_3_loss: 57.9088 - concatenate_4_loss: 181.1337 - val_loss: 372.1027 - val_concatenate_2_loss: 82.0007 - val_concatenate_3_loss: 78.0433 - val_concatenate_4_loss: 212.0586
           precision    recall  F1-score  gts  dets
RBC         0.178571  0.946237  0.300444  465  2464
WBC         0.000000  0.000000       NaN   37   758
Platelets   0.001669  0.051282  0.003234   39  1198