
Loading Dataset
shape of testing label[0]: (36, 13, 13, 8)
shape of testing label[1]: (36, 26, 26, 8)
shape of testing label[2]: (36, 52, 52, 8)
shape of testing img: (36, 416, 416, 3)
shape of validation label[0]: (36, 13, 13, 8)
shape of validation label[1]: (36, 26, 26, 8)
shape of validation label[2]: (36, 52, 52, 8)
shape of validation img: (36, 416, 416, 3)
shape of training label[0]: (296, 13, 13, 8)
shape of training label[1]: (296, 26, 26, 8)
shape of training label[2]: (296, 52, 52, 8)
shape of training img: (296, 416, 416, 3)
epoch  1: loss = 0.1396
epoch  2: loss = 0.0661
epoch  3: loss = 0.0460
epoch  4: loss = 0.0241
epoch  5: loss = 0.0179
epoch  6: loss = 0.0135
epoch  7: loss = 0.0113
epoch  8: loss = 0.0126
epoch  9: loss = 0.0123
epoch 10: loss = 0.0150
epoch 11: loss = 0.0165
epoch 12: loss = 0.0172
epoch 13: loss = 0.0164
epoch 14: loss = 0.0170
epoch 15: loss = 0.0146
epoch 16: loss = 0.0148
epoch 17: loss = 0.0134
epoch 18: loss = 0.0104
epoch 19: loss = 0.0114
epoch 20: loss = 0.0073
epoch 21: loss = 0.0086
epoch 22: loss = 0.0089
epoch 23: loss = 0.0091
epoch 24: loss = 0.0079
epoch 25: loss = 0.0048
epoch 26: loss = 0.0043
epoch 27: loss = 0.0052
epoch 28: loss = 0.0064
epoch 29: loss = 0.0058
epoch 30: loss = 0.0053
epoch 31: loss = 0.0043
epoch 32: loss = 0.0044
epoch 33: loss = 0.0056
epoch 34: loss = 0.0040
epoch 35: loss = 0.0054
epoch 36: loss = 0.0071
epoch 37: loss = 0.0081
epoch 38: loss = 0.0067
epoch 39: loss = 0.0050
epoch 40: loss = 0.0042
epoch 41: loss = 0.0055
epoch 42: loss = 0.0058
epoch 43: loss = 0.0055
epoch 44: loss = 0.0053
epoch 45: loss = 0.0034
epoch 46: loss = 0.0021
epoch 47: loss = 0.0015
epoch 48: loss = 0.0014
epoch 49: loss = 0.0011
epoch 50: loss = 0.0014
epoch 51: loss = 0.0019
epoch 52: loss = 0.0021
epoch 53: loss = 0.0019
epoch 54: loss = 0.0016
epoch 55: loss = 0.0013
epoch 56: loss = 0.0017
epoch 57: loss = 0.0021
epoch 58: loss = 0.0020
epoch 59: loss = 0.0021
epoch 60: loss = 0.0016
epoch 61: loss = 0.0024
epoch 62: loss = 0.0028
epoch 63: loss = 0.0015
epoch 64: loss = 0.0018
epoch 65: loss = 0.0020
epoch 66: loss = 0.0031
epoch 67: loss = 0.0052
epoch 68: loss = 0.0062
epoch 69: loss = 0.0063
epoch 70: loss = 0.0056
epoch 71: loss = 0.0055
epoch 72: loss = 0.0049
epoch 73: loss = 0.0050
epoch 74: loss = 0.0036
epoch 75: loss = 0.0024
epoch 76: loss = 0.0012
epoch 77: loss = 0.0015
epoch 78: loss = 0.0016
epoch 79: loss = 0.0017
epoch 80: loss = 0.0028
epoch 81: loss = 0.0013
epoch 82: loss = 0.0007
epoch 83: loss = 0.0005
epoch 84: loss = 0.0002
epoch 85: loss = 0.0002
epoch 86: loss = 0.0000
Epoch 1/2
WARNING:tensorflow:AutoGraph could not transform <function wrap_yolo_loss.<locals>.yolo_loss at 0x7f5e60207a60> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: invalid syntax (tmp2tlpwtrr.py, line 39)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <function wrap_yolo_loss.<locals>.yolo_loss at 0x7f5ef9f8db80> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: invalid syntax (tmp_hbwjaju.py, line 39)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <function wrap_yolo_loss.<locals>.yolo_loss at 0x7f5ef9f8d040> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: invalid syntax (tmpva6nh91d.py, line 39)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 4/60 [=>............................] - ETA: 21s - loss: 1079.1398 - concatenate_2_loss: 189.5698 - concatenate_3_loss: 222.1595 - concatenate_4_loss: 667.4105











60/60 [==============================] - 37s 424ms/step - loss: 603.8085 - concatenate_2_loss: 121.3879 - concatenate_3_loss: 127.1949 - concatenate_4_loss: 355.2256 - val_loss: 383.7553 - val_concatenate_2_loss: 97.3327 - val_concatenate_3_loss: 92.8758 - val_concatenate_4_loss: 193.5468
Epoch 2/2












60/60 [==============================] - 26s 428ms/step - loss: 167.4103 - concatenate_2_loss: 56.0945 - concatenate_3_loss: 38.1402 - concatenate_4_loss: 73.1755 - val_loss: 269.5303 - val_concatenate_2_loss: 72.4650 - val_concatenate_3_loss: 64.5268 - val_concatenate_4_loss: 132.5385
           precision    recall  F1-score  gts  dets
RBC         0.200455  0.948387  0.330957  465  2200
WBC         0.026144  0.540541  0.049875   37   765
Platelets   0.007890  0.205128  0.015195   39  1014