
Loading Dataset
shape of testing label[0]: (36, 13, 13, 8)
shape of testing label[1]: (36, 26, 26, 8)
shape of testing label[2]: (36, 52, 52, 8)
shape of testing img: (36, 416, 416, 3)
shape of validation label[0]: (36, 13, 13, 8)
shape of validation label[1]: (36, 26, 26, 8)
shape of validation label[2]: (36, 52, 52, 8)
shape of validation img: (36, 416, 416, 3)
shape of training label[0]: (296, 13, 13, 8)
shape of training label[1]: (296, 26, 26, 8)
shape of training label[2]: (296, 52, 52, 8)
shape of training img: (296, 416, 416, 3)
epoch  1: loss = 0.1167
epoch  2: loss = 0.0330
epoch  3: loss = 0.0218
epoch  4: loss = 0.0157
epoch  5: loss = 0.0140
epoch  6: loss = 0.0125
epoch  7: loss = 0.0106
epoch  8: loss = 0.0076
epoch  9: loss = 0.0077
epoch 10: loss = 0.0074
epoch 11: loss = 0.0076
epoch 12: loss = 0.0087
epoch 13: loss = 0.0094
epoch 14: loss = 0.0086
epoch 15: loss = 0.0078
epoch 16: loss = 0.0053
epoch 17: loss = 0.0042
epoch 18: loss = 0.0033
epoch 19: loss = 0.0037
epoch 20: loss = 0.0052
epoch 21: loss = 0.0052
epoch 22: loss = 0.0072
epoch 23: loss = 0.0051
epoch 24: loss = 0.0052
epoch 25: loss = 0.0063
epoch 26: loss = 0.0101
epoch 27: loss = 0.0109
epoch 28: loss = 0.0073
epoch 29: loss = 0.0058
epoch 30: loss = 0.0048
epoch 31: loss = 0.0039
epoch 32: loss = 0.0034
epoch 33: loss = 0.0031
epoch 34: loss = 0.0035
epoch 35: loss = 0.0040
epoch 36: loss = 0.0037
epoch 37: loss = 0.0034
epoch 38: loss = 0.0032
epoch 39: loss = 0.0032
epoch 40: loss = 0.0029
epoch 41: loss = 0.0019
epoch 42: loss = 0.0016
epoch 43: loss = 0.0013
epoch 44: loss = 0.0015
epoch 45: loss = 0.0016
epoch 46: loss = 0.0018
epoch 47: loss = 0.0019
epoch 48: loss = 0.0023
epoch 49: loss = 0.0025
epoch 50: loss = 0.0029
epoch 51: loss = 0.0026
epoch 52: loss = 0.0026
epoch 53: loss = 0.0024
epoch 54: loss = 0.0032
epoch 55: loss = 0.0048
epoch 56: loss = 0.0058
epoch 57: loss = 0.0043
epoch 58: loss = 0.0058
epoch 59: loss = 0.0062
epoch 60: loss = 0.0063
epoch 61: loss = 0.0048
epoch 62: loss = 0.0043
epoch 63: loss = 0.0054
epoch 64: loss = 0.0030
epoch 65: loss = 0.0026
epoch 66: loss = 0.0015
epoch 67: loss = 0.0022
epoch 68: loss = 0.0022
epoch 69: loss = 0.0024
epoch 70: loss = 0.0022
epoch 71: loss = 0.0020
epoch 72: loss = 0.0008
epoch 73: loss = 0.0007
epoch 74: loss = 0.0005
epoch 75: loss = 0.0005
epoch 76: loss = 0.0003
epoch 77: loss = 0.0003
epoch 78: loss = 0.0004
epoch 79: loss = 0.0008
epoch 80: loss = 0.0006
epoch 81: loss = 0.0007
epoch 82: loss = 0.0010
epoch 83: loss = 0.0008
epoch 84: loss = 0.0003
epoch 85: loss = 0.0010
epoch 86: loss = 0.0002
epoch 87: loss = 0.0008
epoch 88: loss = 0.0012
epoch 89: loss = 0.0015
epoch 90: loss = 0.0022
epoch 91: loss = 0.0017
epoch 92: loss = 0.0026
epoch 93: loss = 0.0032
epoch 94: loss = 0.0026
epoch 95: loss = 0.0027
epoch 96: loss = 0.0030
epoch 97: loss = 0.0025
epoch 98: loss = 0.0016
epoch 99: loss = 0.0004
epoch 100: loss = 0.0004
epoch 117: loss = 0.0003
epoch 102: loss = 0.0005
epoch 103: loss = 0.0006
epoch 104: loss = 0.0011
epoch 105: loss = 0.0009
epoch 106: loss = 0.0011
epoch 107: loss = 0.0013
epoch 108: loss = 0.0012
epoch 109: loss = 0.0005
epoch 110: loss = 0.0006
epoch 111: loss = 0.0007
epoch 112: loss = 0.0005
epoch 113: loss = 0.0006
epoch 114: loss = 0.0008
epoch 115: loss = 0.0003
epoch 116: loss = 0.0005
epoch 117: loss = 0.0003
epoch 118: loss = 0.0002
epoch 119: loss = 0.0003
epoch 120: loss = 0.0001
epoch 121: loss = 0.0000
Epoch 1/2
WARNING:tensorflow:AutoGraph could not transform <function wrap_yolo_loss.<locals>.yolo_loss at 0x7f5de03a9f70> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: invalid syntax (tmpcsm2sg_8.py, line 39)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <function wrap_yolo_loss.<locals>.yolo_loss at 0x7f5de04e6a60> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: invalid syntax (tmp684punm2.py, line 39)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <function wrap_yolo_loss.<locals>.yolo_loss at 0x7f5de04e6310> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: invalid syntax (tmp3ld282u4.py, line 39)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 4/60 [=>............................] - ETA: 24s - loss: 1645.9837 - concatenate_2_loss: 224.2101 - concatenate_3_loss: 386.4669 - concatenate_4_loss: 1035.3067













60/60 [==============================] - 44s 507ms/step - loss: 967.1907 - concatenate_2_loss: 142.5973 - concatenate_3_loss: 226.2127 - concatenate_4_loss: 598.3808 - val_loss: 543.2567 - val_concatenate_2_loss: 118.9174 - val_concatenate_3_loss: 134.9292 - val_concatenate_4_loss: 289.4100
Epoch 2/2














60/60 [==============================] - 28s 469ms/step - loss: 288.9385 - concatenate_2_loss: 76.2455 - concatenate_3_loss: 68.6462 - concatenate_4_loss: 144.0468 - val_loss: 317.2949 - val_concatenate_2_loss: 81.7338 - val_concatenate_3_loss: 81.6694 - val_concatenate_4_loss: 153.8917
           precision    recall  F1-score  gts  dets
RBC         0.192032  0.922581  0.317896  465  2234
WBC         0.000000  0.000000       NaN   37   708
Platelets   0.021242  0.333333  0.039939   39   612